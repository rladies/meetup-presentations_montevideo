---
title: <span style="color:#000000">Bosques aleatorios basados en proyecciones </span>
author: <span style="color:#000000"> <font size="6">Natalia da Silva, UDELAR-IESTA</span></font>

date: <span style="color:#000000"> 27 de Octubre, 2017
output: ioslides_presentation
bibliography: bibliophd.bib
---



 <style>
 .title-slide {
     background-image: url(figure/paint1.png);
     background-repeat: no-repeat;
     padding:40px;
     background-size: 1000px 800px;
   }
   </style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## <span style="color:#26734d">Estructura de la presentación</span> 
- Motivación

- Bosques aleatorios de clasificación basados en proyecciones (PPforest) 

- Visualización de modelos de agregación 

- Comentarios finales

## <span style="color:#26734d">Motivación</span> 

**Bosques aleatoreos** [@breiman2001random] es un métodos de supervisado de agregación ampliamente utilizado y competitivo respecto a otros.

Dos propuestas de agrupación basadas en árboles:

- Basada en árboles ortogonales 

- Basada en árboles oblicuos 
<!-- partiendo el espacio de las varibles predictoras por hyperplanos seleccionados aleatoriamente -->


**Black box model**, tener mejores herramientas para diagnosticar y explorar estos modelos permitirán un mejor entendimiento de las fortalezas y debilidades de los mismos.

<!-- - Aprendizaje supervisado: cuando el objetivo es predecir una variable categórica, problema de clasificación ( dos clases o múltiples clases) -->

<!-- - **PPforest** es un nuevo método supervisado de agregación basado en árboles de proyección baggeados para clasificación. -->

<!-- - Este método mejora la capacidad predictiva cuando la separación entre las clases se da en combinaciones lineales de variables. -->

<!-- ## <span style="color:#26734d"> Modelos de agregación</span>  -->
<!-- - Métodos de agregación: combina múltiples modelos individuales entrenados independientemente para construir un modelo de predicción. -->

<!-- - Algunos ejemplos bien conocidos son;  boosting [@schapire1990strength], bagging [@breiman1996bagging] y random forest [@breiman2001random] entre otros. -->

<!-- - La diferencia principal entre los métodos de agregación son;  el tipo de modelos individuales a ser combinados y la forma en que estos modelos son combinados. -->

## <span style="color:#26734d">PPforest </span>  

 **PPforest** bosque aleatorio basado en proyecciones para clasificación.
 
Clasificador individual **PPtree**[@lee2013pptree], usa combinaciones lineales de variables en la partición del nodo, separa las clases teniendo en cuenta la correlación entre las variables.

Conceptos claves en PPforest:

* Agregación Bootstrap (@breiman1996bagging y @breiman1996heuristics)

* Selección aleatoria de variables (@amit1997shape y @ho1998random) en los árboles de clasificación individuales para predicción.



<!-- ## <span style="color:#26734d">PP: projection pursuit</span> -->
<!-- - PP es la forma de encontrar proyecciones interesantes en bajas dimensiones usando un índice de proyección y procedimientos de optimización. -->

<!-- - Para encontrar proyecciones interesantes el índice PP seleccionado es maximizado. -->

<!-- - Proyecciones interesantes para problemas de clasificación son aquellas que permiten ver las clases más separadas. -->

<!-- ## <span style="color:#26734d">PPforest, clasificador individual </span>   -->
<!-- El clasificador individual en  **PPforest** is un **PPtree** [@lee2005projection]. -->

<!-- Trata los datos siempre como un sistema de dos clases. -->

<!-- Cuando las clases son más que dos, el algoritmo usa dos pasos de optimización del índice de proyección  en cada partición del nodo. -->

<!-- The splits in **PPforest** are based on a linear combination of randomly chosen variables. -->
<!-- Utilizing linear combinations of variables the individual model (**PPtree**) separates classes taking into account the correlation between variables. -->

<!-- ## <span style="color:#26734d"> PPtree, individual classifier for PPforest  </span>  -->
<!-- Combines tree structure methods with projection pursuit dimension reduction. -->



## <span style="color:#26734d"> PPtree: Ilustración del algoritmo</span>
<img src="figure/diag2.png" width="700px"/>

## <span style="color:#26734d"> CART vs PPtree, datos simulados</span>
```{r libs, echo = FALSE, warning = FALSE, message=FALSE,fig.align="center"}
library(MASS)
library(ggplot2)
library(RColorBrewer)
library(PPtreeViz)
library(gridExtra)
library(reshape2)
library(PPforest)
library(plyr)
library(plotly)
library(dplyr)
library(GGally)
library(tidyr)

```
<center>
```{r, echo = FALSE, fig.height = 4, fig.width = 7, cache = TRUE, warning = FALSE, message=FALSE,fig.align="center", strip.white=TRUE }
simu3 <- function(mux1, mux2, muy1, muy2, muz1, muz2,  cor1,cor2,cor3) {
  set.seed(666)
  bivn <- mvrnorm(100, mu = c(mux1, mux2), Sigma = matrix(c(1, cor1, cor1, 1), 2))
  bivn2 <- mvrnorm(100, mu = c(muy1, muy2), Sigma = matrix(c(1, cor2, cor2, 1), 2))
  bivn3 <- mvrnorm(100, mu = c(muz1, muz2), Sigma = matrix(c(1, cor3, cor3, 1), 2))

  d1 <- data.frame(Sim = "sim1", bivn)
  d2 <- data.frame(Sim = "sim2", bivn2)
  d3 <- data.frame(Sim = "sim3", bivn3)
  rbind(d1, d2, d3)
}

dat.pl2 <- simu3(-1,0.6,0,-0.6, 2,-1,0.95, 0.95, 0.95)

grilla <- base::expand.grid(X1 = seq(-4,4.8,,100), X2 = seq(-4.3,3.3,,100))

pptree <- PPtreeViz::PPTreeclass(Sim~., data = dat.pl2, "LDA")
ppred.sim <- PPtreeViz::PPclassify(pptree, test.data = grilla, Rule = 1)
grilla$ppred<-ppred.sim[[2]]

rpart.crab <- rpart::rpart(Sim ~ X1 + X2, data = dat.pl2)
rpart.pred <- predict(rpart.crab, newdata = grilla, type="class")

p <- ggplot2::ggplot(data = grilla ) +
  ggplot2::geom_point(ggplot2::aes(x = X1, y = X2, color = as.factor(ppred),shape=as.factor(ppred)),alpha = .20)+
  geom_abline(intercept= pptree$splitCutoff.node[[1]]/pptree$projbest.node[[3]], slope= -pptree$projbest.node[[1]]/pptree$projbest.node[[3]], size=1 )+ scale_colour_brewer(name="Class",type="qual",palette="Dark2")+ggplot2::theme_bw() +
  geom_abline(intercept= pptree$splitCutoff.node[[2]]/pptree$projbest.node[[4]], slope=-pptree$projbest.node[[2]]/pptree$projbest.node[[4]],size=1)+ scale_shape_discrete(name='Class')

pl.pp <- p + ggplot2::geom_point(data = dat.pl2, ggplot2::aes(x = X1 , y = X2, group= Sim, shape = Sim, color=Sim), size = I(3)  ) + theme(legend.position = "bottom", legend.text = element_text(size = 6), aspect.ratio = 1) + scale_y_continuous(expand = c(0,0)) + scale_x_continuous(expand = c(0,0)) + 
  labs(title = "PPtree (PPtreeViz)")

p2 <- ggplot2::ggplot(data = grilla ) + ggplot2::geom_point(ggplot2::aes(x = X1, y = X2  , color = as.factor(rpart.pred),shape =  as.factor(rpart.pred)), alpha = .2) +
  ggplot2::scale_colour_brewer(name = "Class",labels = levels(dat.pl2$Sim),type="qual",palette="Dark2") +
  ggplot2::theme_bw() + scale_shape_discrete(name='Class')+ scale_y_continuous(expand = c(0,0)) + scale_x_continuous(expand = c(0,0))

pl.rpart <- p2 + ggplot2::geom_point(data = dat.pl2, ggplot2::aes(x = X1 , y = X2, group=Sim,shape = Sim, color=Sim), size = I(3)  ) + theme(legend.position = "bottom", legend.text = element_text(size = 6), aspect.ratio = 1) +
  labs(title = "CART (rpart)")

grid.arrange(pl.rpart,pl.pp,ncol=2)

```
</center>


<!-- ## <span style="color:#26734d">PPforest</span> -->
<!-- PPforest es un método de aprendizaje de agregación construido con PPtrees. -->

<!-- - Definición formal -->

<!-- - Implementación -->

<!-- - Diagnósticos y Visualización  -->

<!-- Projection pursuit classification random forest [@dasilvappforest] is an ensemble learning method, built on bagged trees. -->

<!-- Main concepts: -->

<!-- * Bootstrap aggregation (@breiman1996bagging and @breiman1996heuristics)-->

<!-- * Random feature selection (@amit1997shape and @ho1998random) to individual classification trees for prediction. -->

<!-- The splits in PPforest are based on a linear combination of randomly chosen variables. -->
<!-- Utilizing linear combinations of variables the individual model (PPtree) separates classes taking into account the correlation between variables. -->

<!-- ##<span style="color:#26734d">PPforest definición formal</span> -->

<!-- * $\mathbf{X}\in R^p$: vector aleatorio de variables predictoras -->
<!-- * $Y \in \mathscr{G}$ variable aleatoria a predecir (output)  -->
<!-- * $\mathscr{G}$ es un conjunto finito tal que $\mathscr{G}=\{1,2, \ldots, G\}$.  -->
<!-- * La muestra de entrenamiento es definida como $D_n=\{(X_1,Y_1), ..., (X_n, Y_n)\}$ de i.i.d $\Re^p \times \mathscr{G}$ variables aleatorias $(p\geq 2)$.-->

<!-- El objetivo es construir un clasificador que prediga $y$ con $\mathbf{x}$ usando $D_n$ dado un clasificador agregado  $\{h_n\}$. -->

<!-- ##<span style="color:#26734d">PPforest definición formal</span> -->

<!--  Clasificador PPforest: -->

<!-- * Una colección de árboles de clasificación aleatorios $\{h_n(\mathbf{x}, \Theta_m, D_n), m\geq 1\}$  donde $\{\Theta_m\}$ son i.i.d. vectores aleatorios.-->

<!-- * $\Theta_m$, contiene las dos fuentes de aleatoriedad en el árbol (la selección aleatoria de variables y la muestra aleatoria bootstrap),  -->
<!-- <!-- then $\Theta_m$ has information about which variables were selected in each partition and which cases were selected in the bootstrap sample. --> 

<!-- Para cada árbol, $h_n$, un voto único es considerado basado en la clase más popular y el predictor final se basa en la clase más votada en el bosque. -->


<!-- ##<span style="color:#26734d">PPforest formal definition</span> -->
<!-- PPF estimator based on combining the trees: -->
<!-- $$ -->
<!-- \begin{aligned} -->
<!-- f_n(\mathbf{X}, D_n )&=& \operatorname*{arg\,max}_{g\in \mathscr{G}} \{E_{\Theta}(I[h_n(\mathbf{X}, \Theta, D_n)=g])\}\\ \nonumber -->
<!-- &=& \operatorname*{arg\,max}_{g\in \mathscr{G}} P_{\Theta}(h_n(\mathbf{X}, \Theta, D_n)=g) -->
<!-- \end{aligned} -->
<!-- $$ -->


##<span style="color:#26734d">PPforest: Ilustración del algoritmo</span> 
<img src="figure/diagram.png" width="700px"/>


##<span style="color:#26734d">PPforest: Implementación </span>
* Implementado en un paquete de R **PPforest**

* Versión inicial de **PPforest** enteramente en R.

* Dos estrategias para optimizar el código fueron empleadas:

     - Funciones principales en Rcpp (integración de R con C++)
     
     - Paralelización

##<span style="color:#26734d">PPforest: Tiempo de procesamiento</span>
<!-- <img src="figure/resus-1.pdf" vspace="1"  "width="700px"/> -->

```{r echo=FALSE, warning=FALSE, message=FALSE}
load("preformance_timesWTplyr.Rdata")
global_labeller <- labeller(
 g = class,
 ntrees = trees,
 .default = label_both
)
mm.allbig <- bind_rows(mm.new, mm.old) %>%
  rename(p=ps, g=gs, n=ns, ntrees=mtrees) %>%
  mutate(version = recode(version, new="post", old="pre")) %>%
  mutate(seconds = time/1e9)
mm.allbig$version <- factor(mm.allbig$version, levels = c("pre","post"))
levels(mm.allbig$version) <- c("Only in R", "Rcpp & parallelization")
ggplot(data = mm.allbig) +
    geom_smooth(aes(g, seconds, color = version,
                        linetype = version), method="lm") +
    geom_jitter(aes(g, seconds, color = version, shape = version),
               alpha = .4, size = 3, height = 0) +
    scale_x_continuous(breaks=seq(0,10,2)) +
    labs(x = "Num. groups", y = "Time (sec)") +
    scale_colour_brewer(name = "", type = "qual",
                      palette = "Dark2") +
    scale_shape(name = "") +
    scale_linetype(name = "") +
    facet_grid(ntrees~n + p, labeller = label_both,
                scales = "free_y") +
    #scale_x_continuous(trans = 'log2') +
    theme(legend.position = "bottom",
        axis.text = element_text(size = 6), aspect.ratio = 1 )

```

##<span style="color:#26734d">PPforest: Diagnósticos</span> 


Para entender mejor los modelos agregados y poder evaluarlos, algunos diagnósticos pueden ser definidos:

- Matriz de proximidades 

<!-- :calculated for every pair of observations, if cases $k_i$ and $k_j$ are in the same terminal node increase their proximity by one. Normalize  by the number of trees.  -->


- Matriz de votos
<!-- : one row for each input data point and one column for each class, giving the number of (OOB) votes for each class.   -->

- Importancia de las variables

- Tasa de error OOB
<!-- : OOB error, proportion of times that case $n$ is wrong classified  averaged over all cases is the oob error estimate.  -->

Segunda motivación, construir herramientas para explorar, entender y diagnosticar "black box models"

## <span style="color:#26734d">Visualización de modelos agregados de clasificación </span> 

Para explorar y diagnosticar modelos de bosques de clasificación se diseña una aplicación interactiva con tres niveles de análisis.
 
 1. **Casos individuales (observaciones)**
 2. **Modelos individuales (árboles)**
 3. **Comparación de la performance (PPF vs RF)**
 
Marco conceptual propuesto por [@wickham2015visualizing] para visualizar modelos estadísticos.

Clave en nuestra aplicación es el uso de métodos de visualización interactiva. 


## <span style="color:#26734d">Gráficos interactivos </span>
 
 Dos tareas claves que una visualización interactiva debería cumplir:
 
 * Interacciones en cada visualización individual
 * Links entre distintos gráficos
 
 ¿Por qué usar visualización interactiva?
 
 Permite identificar conexiones al interior de cada nivel que no pueden ser vistos en gráficos estáticos.

<!-- - Los links a nivel de las observaciones permiten identificar casos donde el modelo no está funcionando bien y nos permite caracterizar la observación basado en los datos originales. -->

<!-- - También podemos identificar modelos individuales en el modelo agregado que no es suficientemente bueno e identificar porque esto está pasando.  -->

<!-- - El último nivel de análisis se enfoca en la comparación de modelos basado en la capacidad predictiva para cada clase. -->


<!-- ## <span style="color:#26734d">Marco conceptual </span> -->
<!-- Tres estrategias [@wickham2015visualizing]: -->

<!-- - Visualizar el modelo en el espacio de los datos -->

<!-- - Observar todos los miembros de una colección -->

<!-- - Explorar el proceso completo -->


##<span style="color:#26734d">Ejemplo: Fishcatch </span>
159 observaciones de peces de 7 especies (Bream, Parkki, Perch, Pike, Roach, Smelt y Whitewish) son capturados y medidos, 6 variables.

Variable|Descripción
------------|------------------------------------------------------
weight| Peso del pez (en gramos)
length1| Longitud desde la nariz al inicio de la cola (en cm)
length2| Longitud desde la nariz hasta la muesca de la cola (en cm)
length3| Longitud desde la nariz hasta el final de la cola (en cm)
height|  Altura máxima como  % de length3
width|   Ancho máximo como % de length3


## <span style="color:#26734d">Panel 1: Diagrama del nivel observacional</span>

<img src="figure/fishT1.png" height="450px" width="700px"/>

##<span style="color:#26734d">Ejemplo: Fishcatch </span>

  
```{r hola, echo = FALSE, fig.height = 5, fig.width = 8, warning = FALSE, message=FALSE,fig.align="center",  warning = FALSE, message=FALSE}
library(devtools)
#install_github("natydasilva/PPforest")
library(PPforest)
library(ggplot2)
library(tidyr)
library(dplyr)
library(plotly)
library("vembedr")
load("ppf3.RData")


ppf <- ppf3

myscale <- function(x) (x - mean(x)) / sd(x)
scale.dat <- ppf$train %>% mutate_each(funs(myscale),-matches(ppf$class.var)) 
scale.dat.melt <- scale.dat %>%  mutate(ids = 1:nrow(ppf$train)) %>% gather(var,Value,-Type,-ids)
scale.dat.melt$Variables <- as.numeric(as.factor(scale.dat.melt$var))
colnames(scale.dat.melt)[1] <- "Class"
scale.dat.melt$Value <- round(scale.dat.melt$Value ,3)

p <- ggplot(scale.dat.melt, aes(x = Variables, y = Value, 
                                    group = ids, key = ids, colour = Class, var = var)) +
      geom_line(alpha = 0.3) + scale_x_discrete(limits = levels(as.factor(scale.dat.melt$var)), expand = c(0.01,0.01)) +
      ggtitle("Data parallel plot ") + theme(legend.position = "none", axis.text.x  = element_text(angle = 90, vjust = 0.5)) + 
      scale_colour_brewer(type = "qual", palette = "Dark2")
 plotly::ggplotly(p,tooltip = c("var","colour","y","key"))   

```




## <span style="color:#26734d">Proximity Matrix</span>

<center>
```{r, echo=FALSE,fig.height=5,fig.width=5,  warning = FALSE, message=FALSE,fig.align="center", cache=TRUE}
k <- 2
id <- diag(dim(ppf$train)[1])
id[lower.tri(id, diag = TRUE)] <- 1 - ppf[[9]]$proxi
rf.mds <- stats::cmdscale(as.dist(id), eig = TRUE, k = k)
colnames(rf.mds$points) <- paste("MDS", 1:k, sep = "")
nlevs <- nlevels(ppf$train[, 1])



f.helmert <- function(d)
{
  helmert <- rep(1 / sqrt(d), d)
  for (i in 1:(d - 1))
  {
    x <- rep(1 / sqrt(i * (i + 1)), i)
    x <- c(x,-i / sqrt(i * (i + 1)))
    x <- c(x, rep(0, d - i - 1))
    helmert <- rbind(helmert, x)
  }
  return(helmert)
}

#projected data
projct <- t(f.helmert(length(unique(ppf$train[,ppf$class.var])))[-1,])

bestnode <- plyr::ldply(ppf[[8]][[2]], function(x) {
  bn <- abs(x$projbest.node)
  bn[bn == 0] <- NA
  dat.fr <- data.frame(node = 1:dim(x$projbest.node)[1],bn)
  
})

colnames(bestnode)[-1] <- colnames(ppf$train[,-which(colnames(ppf$train)==ppf$class.var)])
bestnode$node <- as.factor(bestnode$node)


data <- data.frame(
        MDS1 = rf.mds$points[,1], MDS2 = rf.mds$points[,2],
        Class = ppf$train[, 1],ids = 1:nrow(rf.mds$points),
        fill = logical(nrow(ppf$train)),proj.vote =
          as.matrix(ppf$votes) %*% projct,
        vote = ppf$votes, pred = ppf$prediction.oob, scale.dat
        )
data$MDS1 <- round(data$MDS1,3)
data$MDS2 <- round(data$MDS2,3)


p2 <- ggplot(data = data, aes(x = MDS1, y = MDS2, 
                                    colour = Class, key = ids)) + 
      geom_point(size = I(3),alpha = .5)  + theme(legend.position = "none", legend.text = element_text(angle = 90), legend.key = element_blank(), aspect.ratio =
        1)  + labs(y = "MDS 2", x = "MDS 1", title = "Multidimensional Scaling") +
     scale_colour_brewer(type = "qual",palette = "Dark2")
    
ggplotly(p2,tooltip = c("colour","x","y","key"))

```
</center>


## <span style="color:#26734d"> Matríz de votos, Jittered side-by-side dot plot</span>
<center>
```{r, echo=FALSE,fig.height=5,fig.width=7,fig.align="center", warning=FALSE,message=FALSE}
library(stringr)
 reddat <- data %>% 
            select(ids, Class, starts_with("vote"), pred) 
      colnames(reddat) <- colnames( reddat) %>% str_replace("vote.","")
   
      sidepl <- reddat %>% gather(classpred, Proportion, -pred, -ids, -Class) %>% mutate(Proportion= round(Proportion,3))
   
  
    p <- ggplot(data = sidepl, aes(classpred, Proportion, colour = Class, key = ids)) + 
      geom_jitter(height = 0, size = I(3), alpha = .5) +
      theme(axis.text.x  = element_text(angle = 45, vjust = 0.5), aspect.ratio = 1) +
      labs(x = "Class", title = "Side by side plot", y ="Proportion", color="True class") + scale_colour_brewer(type = "qual", palette = "Dark2") 
     ggplotly(p,tooltip = c("colour","y","key")) %>% layout(dragmode = "select")
```
</center>


## <span style="color:#26734d">Matríz de votos, ternary plot</span>
* Diagrama triangular muestra la proporción de tres variables que suman una constante y lo hace usando coordinadas baricéntricas.
Podemos dibujar la proporción de tres variables en dos dimensiones. Es útil para visualizar datos composicionales.

* Con más de tres clases el diagrama triangular necesita ser generalizado.
Los datos son proyectados en un espacio $(p-1)-$D. Este método será utilizado para visualizar la matriz de votos.

## <span style="color:#26734d">Matríz de votos, ternary plot</span>
<center>
```{r, echo=FALSE,fig.height=3,fig.width=7,fig.align="center",cache=TRUE, warning = FALSE, message=FALSE}


f.helmert <- function(d)
{
  helmert <- rep(1 / sqrt(d), d)
  for (i in 1:(d - 1))
  {
    x <- rep(1 / sqrt(i * (i + 1)), i)
    x <- c(x, -i / sqrt(i * (i + 1)))
    x <- c(x, rep(0, d - i - 1))
    helmert <- rbind(helmert, x)
  }

  return(helmert)
}

makePairs <- function(dat, id = c(a, b, c)) {
  aux <- dat[,-c(1, 2)]

  d <- aux[, id]

  grid <- expand.grid(x = id, y = id)
  grid <- subset(grid, x != y)
  all <- do.call("rbind", lapply(1:nrow(grid), function(i) {
    xcol <- grid[i, "x"]
    ycol <- grid[i, "y"]
    data.frame(
      Class = dat[, 1],
      ids = dat[, 2],
      x = dat[, xcol+2],
      y = dat[, ycol+2],
      pair = paste(grid[i, ], collapse = '-')
    )
  }))

  all
}

#ppf PPforest object
#V1,v2,v3 select the 3 proj directions
ternarydata <- function(ppf, v1, v2, v3){
  n.class <- ppf$train %>% select_(ppf$class.var) %>% unique() %>% nrow()
  projct <- t(f.helmert(length(unique(ppf$train[, ppf$class.var])))[-1,])

  dat3 <-
    data.frame(
      Class = ppf$train[, ppf$class.var],
      ids = 1:nrow(ppf$train),
      proj.vote = round(as.matrix(ppf$votes) %*% projct,3)
    )

  ##with 3 or less classes
  empt <- rep(1:nrow(dat3), 3)
  #dat3.empt <- dat3[empt, ] %>% mutate(rep = rep(1:3, each = nrow(dat3)))
  if (n.class > 3) {
    gg1 <-  makePairs(dat3, c(v1,  v2, v3))
  }

  gg1 <-  makePairs(dat3, id = c(v1, v2, v3))

  return(gg1)
}



#need to run f_hermite
f_composition <- function(data) {
  d <- dim(data)[2]
  hm <- f.helmert(d)
  x <- data - matrix(1 / d, dim(data)[1], d)
  return((x %*% t(hm))[,-1])
}

simplex <- function(p = 3) {
  vert <- f_composition(diag(p + 1))
  colnames(vert) <- paste0("d", 1:ncol(vert))

  wires <-
    do.call(expand.grid, list(c(1:nrow(vert)), c(1:nrow(vert))))

  structure(list(points = vert,
                 edges = wires[!(wires[, 1] == wires[, 2]),]))
}

##ternary plot
ternaryshell <- function(ppf, sp = 3, dx = 1, dy = 2, v1 = 1, v2 = 2, v3 = 3){
  s <- simplex(sp)
  pts <- data.frame(s$points)
  #pts <- data.frame(s$points[,c(dx,dy)])
  gg1 <- ternarydata(ppf, v1, v2, v3)

  edg <- data.frame(x1=pts[,dx][s$edges[,1]], x2 = pts[,dx][s$edg[,2]],
                    y1=pts[,dy][s$edg[,1]], y2 = pts[,dy][s$edg[,2]])

  p1  <- gg1 %>% filter(pair %in% paste(dx,dy, sep="-") ) %>%
    select(Class, x, y) %>%
    ggplot(aes(x, y, color = Class)) +
      geom_segment(data = edg, aes(x = x1, xend = x2,
                                 y = y1, yend = y2), color = "black" ) +
      geom_point(size = I(3), alpha = .5) +
      labs(y = "",  x = "") +
      theme(legend.position = "none", aspect.ratio = 1) +
      scale_colour_brewer(type = "qual", palette = "Dark2") +
      labs(x = paste0("T",dx,""), y = paste0("T",dy,"")) +
    theme(aspect.ratio=1)

  p1
}

t1 <- ternaryshell(ppf, 6, 1, 2)
t2 <- ternaryshell(ppf, 6, 1, 3)
t3 <- ternaryshell(ppf, 6, 2, 3)
 subplot(t1,t2,t3, titleX=TRUE, titleY=TRUE)
```
</center>





## <span style="color:#26734d">Panel 1: App para el nivel observacional</span>

<iframe class="vimeo-embed" src="https://player.vimeo.com/video/222028803" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen> </iframe>


## <span style="color:#26734d">Panel 2: Modelos</span>

<img src="figure/fishT2.png" height="450px" width="700px"/>

## <span style="color:#26734d">Panel 2: App modelos </span>

<iframe class="vimeo-embed" src="https://player.vimeo.com/video/222029591" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen> </iframe>


## <span style="color:#26734d">Panel 3: Comparación </span>

<img src="figure/fishT3.png" height="450px" width="700px" />

## <span style="color:#26734d">Panel 3: App comparación </span>

<iframe class="vimeo-embed" src="https://player.vimeo.com/video/222029620" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen> </iframe>


<!-- ##<span style="color:#26734d">PPforest performance and comparison</span>  -->

<!-- * Simulation study to understand the PPF performance relative to RF -->
<!-- * Two parameters are varied, $\sigma$ and $\theta$  -->

<!-- <img src="figure/simulation.pdf" width="300px"/> -->

<!-- ##<span style="color:#26734d">PPforest performance and comparison</span>  -->
<!-- <img src="figure/simulation-1.pdf" width="700px"/> -->


<!-- ##<span style="color:#26734d">PPforest performance and comparison</span>  -->
<!-- - Randomly chosen 2/3 observations in training and  1/3 in test to compute predictive error -->
<!-- - Repeat 200 times -->
<!-- ```{r parbench, depenson="benchpl",echo=FALSE, message=FALSE, warning=FALSE, fig.height=6, fig.width=11} -->
<!-- load("table.raw.Rdata") -->
<!-- aux <- table.raw %>% -->
<!--   separate(method, into = c('met', 'b') ) %>% -->
<!--   group_by(data, met) %>% mutate(mm = min(mn.te) ) %>% -->
<!--   filter(mn.te == mm ) %>% select(data, met, mn.tr, mn.te) %>% ungroup() %>% -->
<!--   gather(type, error, mn.tr, mn.te) %>% mutate(met = reorder(met, error) ) %>% -->
<!--   filter(type=="mn.te") %>%unite(gg, data, type, remove = FALSE) %>% -->
<!--   mutate(type = factor(type, labels = "Test"), error = round(error,3)) %>% -->
<!--   #mutate(type = factor(type, labels = c("Training", "Test")), error = round(error,3)) %>%  -->
<!--   filter(type == "Test")  -->
<!--   p1 <- ggplot(aux) + geom_line(aes(x = met, y = error, group = gg, color = data) ) + -->
<!--   scale_x_discrete( expand = c(0.01, 0.01) ) + -->
<!--  # scale_colour_brewer(palette="Dark2") + -->
<!--   labs(y ="Average error rate", x ="Method", colour ="Data")  -->
<!--   #facet_wrap(~type, ncol=2, labeller = label_parsed)  -->
<!--  # theme(legend.position = "bottom") -->
<!-- ggplotly(p1, tooltip = c("met", "error","data"))  -->
<!-- ``` -->
<!-- \caption{Benchmark data results shown graphically. PPF performs consistently well across most of the data sets. \label{parallel}} -->
<!-- \end{figure} -->


<!-- ##<span style="color:#26734d">PPforest performance and comparison</span>  -->

<!-- ```{r echo=FALSE, message=FALSE, cache=TRUE, eval=FALSE} -->
<!-- library(ggplot2) -->
<!-- library(purrr) -->
<!-- library(dplyr) -->
<!-- library(tidyr) -->
<!-- library(knitr) -->
<!-- library(kableExtra) -->

<!-- # load data -->
<!-- ll <- paste('benchmark', list.files('benchmark', pattern = '.ata'), sep='/') -->
<!-- for( i in 1:length(ll) ) load(ll[i]) -->

<!-- # put all data as part of a list -->
<!-- dtnm <- data_frame(nm = list.files('benchmark', pattern = '.ata')) %>% -->
<!--   separate(nm, into=c('nm2', 'mugre'), sep='\\.') -->

<!-- dts <- list() -->
<!-- for (i in 1:length(ll) ) dts[[i]] <- get(dtnm$nm2[i]) -->
<!-- names(dts) <- dtnm$nm2 -->

<!-- ff <- function(x) {  -->
<!--   mm <- c('cart', 'ppf', 'pptr', 'rf') -->
<!--   xi <- list() -->
<!--   for ( i in 1:4) xi[[i]]<- x %>% slice( grep(mm[i], x$method) ) %>% slice(which.min(mn.te)) -->

<!--   bind_rows(xi) %>% mutate(met = mm) %>% -->
<!--     select(met, mn.tr, mn.te) %>%  -->
<!--     gather( type, err, mn.tr, mn.te) %>%  -->
<!--     unite(mm, type, met, sep='_') %>% -->
<!--     spread(mm, err) -->
<!--   } -->

<!-- dt2 <- bind_rows(lapply(dts, ff), .id='data') %>%  -->
<!--   separate(data, into=c('Data','mugre' )) %>% select(-mugre) -->
<!-- dt2 <- dt2[, c(1, 6:9, 2:5)]  -->
<!-- colnames(dt2) <- c('Data', 'CART', 'PPforest', 'PPtree', 'RForest', 'CART', 'PPforest', 'PPtree', 'RForest' ) -->

<!-- # using xtable for latex output -->
<!-- # library(xtable) -->
<!-- #mcol =  list(pos=list(-1), command="& \\multicolumn{4}{c}{TRAINING} & \\multicolumn{4}{c}{TEST} \\\\") -->
<!-- #xtable(dt, digits=3, align=c('l', 'l||', 'r', 'r', 'r', 'r||' , 'r', 'r', 'r', 'r') ) %>% print(add.to.row=mcol, include.rownames=FALSE) -->

<!-- # for r-markdown html output -->
<!-- kable(dt2, digits = 2, format='html') %>% -->
<!--   kable_styling(c("striped", "bordered")) %>% -->
<!--   add_header_above(c(" " , "TRAINING" = 4, "TEST" = 4)) -->
<!-- ``` -->



## <span style="color:#26734d">Comentarios Finales </span>
1. PPF método de clasificación agregado basado en árboles con particiones oblicuas.

2. PPF toma la correlación entre variables en cuenta y mejora la performance de RF cuando la separación ocurre en combinaciones de variables.

3. En estudios de simulación PPF tiene mejor performance que RF cuando las clases pueden ser separadas por combinaciones lineales y la correlación entre variables se incrementa.

## <span style="color:#26734d">Comentarios Finales</span>

1. El tener mejores herramientas que ayuden a entender ``black box models'' nos da un mejore entendimiento de los datos, las fortalezas y debilidades y como el modelo va a funcionar en datos futuros. 

2. La visualización presentada provee una selección de gráficos interactivos para el diagnóstico de los modelos PPF . 

3. Esta estructura puede ser utilizada para hacer una apps para otros clasificadores de agregación. 

4. Combinar shiny, ggplot2 y plotly permite desarrollar visualizaciones interactivas potentes

<!-- 4. The app is implemented with new technology for interactive graphics provided by the `plotly` package. It is one of the first uses of these new tools. -->


<!-- ## <span style="color:#26734d">Some PPforest extensions </span> -->

<!-- 1. Some enhancements of the PPtree algorithm to get a better separation of classes more broadly -->
<!-- 2. Allowing a tree with multiple splits per class can help to tackle nonlinear classification problems. -->

<!-- 3. Viz app extensions that could help it to be a tool for model refinement: -->
<!--     <!-- * Using the diagnostics to weed out under-performing models in the ensemble --> 
<!--     <!-- * Identifying and boosting models that perform well, particularly if they do well for problematic subsets of the data --> 
<!--     * Problematic cases could be removed, and ensembles re-fit -->
<!--     * This tool can be extended to other ensembles, and perhaps a new R package that provides general tools to explore other ensembles will be an useful tool -->
<!--     <!-- * Classes as a whole could be aggregated or re-organised as suggested by the model diagnostics -->


## <span style="color:#26734d">Información </span>

1.  Paquete PPforest:https://github.com/natydasilva/PPforest
2.  Slides: https://github.com/natydasilva/SlidesPPforest
3.  Viz: https://natydasilva.shinyapps.io/shinyppforest/
4.  webpage: http://ndasilva.public.iastate.edu
5.  email: natalia\@iesta.edu.uy  twitter:\@pacocuak


## Bibliografía
